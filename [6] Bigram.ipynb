{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e53499-1ca7-4dd5-8d52-f27322d3de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-30 11:04:59--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  5.56MB/s    in 0.2s    \n",
      "\n",
      "2024-03-30 11:04:59 (5.56 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bd8178-be8d-4e1e-83ee-7e607bd66cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1343d7-8172-47b9-b5b0-9df21a0a8296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fed6ac-be2e-4b32-a117-ef1367b486fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "N_vocab = len(chars)\n",
    "print(''.join(chars))\n",
    "print(N_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f90f033-b326-47e2-8626-18a74fc887a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s : [ stoi[c] for c in s]\n",
    "decode = lambda l : ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "845456fe-4e27-4ba4-be87-18c8ea57b4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14921fcc-7db7-46ed-92d5-fccede538633",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(0.9 * len(data))\n",
    "train_data = data[:N]\n",
    "valid_data = data[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ab9f8e-b72a-4bb5-a3a6-d0abe2f5e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "N_batch = 4\n",
    "N_block = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else valid_data\n",
    "    ix = torch.randint(len(data) - N_block, (N_batch, ))\n",
    "    x = torch.stack([data[i:i+N_block] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+N_block+1] for i in ix])\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8e183-5498-42e2-95bc-4107551bf77b",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a248138-d420-43b8-a1ea-1645712d2629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.7051, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "P-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3!dcb\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, N_vocab):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(N_vocab, N_vocab)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(N_vocab)\n",
    "xb, yb = get_batch('train')\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(model.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa551b7-57f9-4212-82a2-4b026460b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "285af6c7-165b-47fc-a612-340af1232598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsladmin/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5555150508880615\n"
     ]
    }
   ],
   "source": [
    "N_batch = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb  = get_batch('train')\n",
    "\n",
    "    logits, loss = model(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69cc65d1-d1f8-4faf-95b5-613f310da447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ong h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay.JUCle n prids, r loncave w hollular s O:\n",
      "HIs; ht anjx?\n",
      "\n",
      "DUThinqunt.\n",
      "\n",
      "LaZAnde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scace, tridesar, wnl'shenous s ls, theresseys\n",
      "PlorseelapinghiybHen yof GLUCEN t l-t E:\n",
      "I hisgothers je are!-e!\n",
      "QLYotouciullle'z,\n",
      "Th\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f43eba-260c-43d9-aa40-7e1973e169c3",
   "metadata": {},
   "source": [
    "## Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c603e869-9edb-4c89-9591-4482bbfb0cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333]]),\n",
       " tensor([[2., 7.],\n",
       "         [6., 4.],\n",
       "         [6., 5.]]),\n",
       " tensor([[2.0000, 7.0000],\n",
       "         [4.0000, 5.5000],\n",
       "         [4.6667, 5.3333]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a,1,keepdim = True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebc0f5e-053d-4dce-873b-64a2b8e9584a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05c65573-7d15-44d6-a971-24dac336c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49392a26-5098-4ae8-a649-49afefc7490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wt = torch.tril(torch.ones(T,T))\n",
    "wt = wt / wt.sum(1, keepdim = True)\n",
    "xbow2 = wt @ x\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e540ef0c-2df6-4a2c-a791-b6ee55039cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wt = torch.zeros((T,T))\n",
    "wt = wt.masked_fill(tril == 0, float('-inf'))\n",
    "wt = F.softmax(wt, dim = -1)\n",
    "xbow3 = wt @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fa9df7f-4f17-424b-a144-29bde0a7bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([4, 8, 32])\n",
      "k torch.Size([4, 8, 16])\n",
      "q torch.Size([4, 8, 16])\n",
      "W torch.Size([4, 8, 8])\n",
      "O torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "N_head = 16\n",
    "key = nn.Linear(C, N_head, bias = False)\n",
    "query = nn.Linear(C, N_head, bias = False)\n",
    "value = nn.Linear(C, N_head, bias = False)\n",
    "\n",
    "\n",
    "k = key(x) # B, T, 16\n",
    "q = query(x) # B,T,16\n",
    "wt = q @ k.transpose(-2,-1) # B,T,16 @ B,16,T --> B,T,T\n",
    "\n",
    "print('x',x.shape)\n",
    "print('k',k.shape)\n",
    "print('q',q.shape)\n",
    "print('W',wt.shape)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wt = wt.masked_fill(tril == 0, float('-inf'))\n",
    "wt = F.softmax(wt, dim = -1)\n",
    "\n",
    "v = value(x)\n",
    "out = wt @ v\n",
    "\n",
    "print('O',out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37989c4b-f3ca-4af4-9c6b-150d3f395a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdb0ed-6310-4309-b8b2-6bf10ff0ec99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
