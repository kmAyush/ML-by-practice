{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JmbG37hBQX2"
   },
   "source": [
    "# Credit Card Fraud Detection - Standardized Grid Search\n",
    "\n",
    "This notebook implements fraud detection using:\n",
    "- **Algorithms**: Logistic Regression, Random Forest, XGBoost\n",
    "- **Sampling**: SMOTE oversampling and Random undersampling\n",
    "- **Tuning**: **Standardized Grid Search** with cross-validation\n",
    "- **Metrics**: Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDIxBnvUBQX6",
    "outputId": "d7447ee9-ec0f-47c8-efb4-c6dae8d50826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JMbCZn3BQX8"
   },
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NIOJnHFVIrYy"
   },
   "outputs": [],
   "source": [
    "# Dataset link - https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0NVn2DuBWu5",
    "outputId": "5c8e78ba-d9f7-4307-d572-f7ed58ec08be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 72.7M  100 72.7M    0     0  5982k      0  0:00:12  0:00:12 --:--:-- 6740k\n"
     ]
    }
   ],
   "source": [
    "# Obtaining credit card fraud detection dataset\n",
    "!curl -o card_transdata.csv https://raw.githubusercontent.com/marhcouto/fraud-detection/master/data/card_transdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AC4S6UCJBQX9",
    "outputId": "525d3e78-423e-4283-b7cd-f898049216a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000000, 8)\n",
      "\n",
      "Features: ['distance_from_home', 'distance_from_last_transaction', 'ratio_to_median_purchase_price', 'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order']\n",
      "\n",
      "Fraud distribution:\n",
      "fraud\n",
      "0.0    912597\n",
      "1.0     87403\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fraud percentage: 8.74%\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('card_transdata.csv')\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nFeatures: {list(data.columns[:-1])}\")\n",
    "print(f\"\\nFraud distribution:\")\n",
    "print(data['fraud'].value_counts())\n",
    "print(f\"\\nFraud percentage: {data['fraud'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "tXFquh-rBQX-",
    "outputId": "42cabc0a-b970-4833-87f0-9cd07713ba4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2.207101</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>1.626798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>19.872726</td>\n",
       "      <td>2.683904</td>\n",
       "      <td>2.778303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>2.914857</td>\n",
       "      <td>1.472687</td>\n",
       "      <td>0.218075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4.258729</td>\n",
       "      <td>0.242023</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>58.108125</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                57.877857                        0.311140   \n",
       "1                10.829943                        0.175592   \n",
       "2                 5.091079                        0.805153   \n",
       "3                 2.247564                        5.600044   \n",
       "4                44.190936                        0.566486   \n",
       "...                    ...                             ...   \n",
       "999995            2.207101                        0.112651   \n",
       "999996           19.872726                        2.683904   \n",
       "999997            2.914857                        1.472687   \n",
       "999998            4.258729                        0.242023   \n",
       "999999           58.108125                        0.318110   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                             1.945940              1.0        1.0   \n",
       "1                             1.294219              1.0        0.0   \n",
       "2                             0.427715              1.0        0.0   \n",
       "3                             0.362663              1.0        1.0   \n",
       "4                             2.222767              1.0        1.0   \n",
       "...                                ...              ...        ...   \n",
       "999995                        1.626798              1.0        1.0   \n",
       "999996                        2.778303              1.0        1.0   \n",
       "999997                        0.218075              1.0        1.0   \n",
       "999998                        0.475822              1.0        0.0   \n",
       "999999                        0.386920              1.0        1.0   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0                   0.0           0.0    0.0  \n",
       "1                   0.0           0.0    0.0  \n",
       "2                   0.0           1.0    0.0  \n",
       "3                   0.0           1.0    0.0  \n",
       "4                   0.0           1.0    0.0  \n",
       "...                 ...           ...    ...  \n",
       "999995              0.0           0.0    0.0  \n",
       "999996              0.0           0.0    0.0  \n",
       "999997              0.0           1.0    0.0  \n",
       "999998              0.0           1.0    0.0  \n",
       "999999              0.0           1.0    0.0  \n",
       "\n",
       "[1000000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "qmDgHlJPH5o2",
    "outputId": "af34da85-d63b-418a-fc3a-1e3545f40939"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.628792</td>\n",
       "      <td>5.036519</td>\n",
       "      <td>1.824182</td>\n",
       "      <td>0.881536</td>\n",
       "      <td>0.350399</td>\n",
       "      <td>0.100608</td>\n",
       "      <td>0.650552</td>\n",
       "      <td>0.087403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.390784</td>\n",
       "      <td>25.843093</td>\n",
       "      <td>2.799589</td>\n",
       "      <td>0.323157</td>\n",
       "      <td>0.477095</td>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.476796</td>\n",
       "      <td>0.282425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.878008</td>\n",
       "      <td>0.296671</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.967760</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.743985</td>\n",
       "      <td>3.355748</td>\n",
       "      <td>2.096370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10632.723672</td>\n",
       "      <td>11851.104565</td>\n",
       "      <td>267.802942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance_from_home  distance_from_last_transaction  \\\n",
       "count      1000000.000000                  1000000.000000   \n",
       "mean            26.628792                        5.036519   \n",
       "std             65.390784                       25.843093   \n",
       "min              0.004874                        0.000118   \n",
       "25%              3.878008                        0.296671   \n",
       "50%              9.967760                        0.998650   \n",
       "75%             25.743985                        3.355748   \n",
       "max          10632.723672                    11851.104565   \n",
       "\n",
       "       ratio_to_median_purchase_price  repeat_retailer       used_chip  \\\n",
       "count                  1000000.000000   1000000.000000  1000000.000000   \n",
       "mean                         1.824182         0.881536        0.350399   \n",
       "std                          2.799589         0.323157        0.477095   \n",
       "min                          0.004399         0.000000        0.000000   \n",
       "25%                          0.475673         1.000000        0.000000   \n",
       "50%                          0.997717         1.000000        0.000000   \n",
       "75%                          2.096370         1.000000        1.000000   \n",
       "max                        267.802942         1.000000        1.000000   \n",
       "\n",
       "       used_pin_number    online_order           fraud  \n",
       "count   1000000.000000  1000000.000000  1000000.000000  \n",
       "mean          0.100608        0.650552        0.087403  \n",
       "std           0.300809        0.476796        0.282425  \n",
       "min           0.000000        0.000000        0.000000  \n",
       "25%           0.000000        0.000000        0.000000  \n",
       "50%           0.000000        1.000000        0.000000  \n",
       "75%           0.000000        1.000000        0.000000  \n",
       "max           1.000000        1.000000        1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XudLfndEBQX-"
   },
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTVM2J2rBQX-",
    "outputId": "506a48ce-6252-47c7-d4e1-7954b903b17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 700000 samples\n",
      "Test set: 300000 samples\n",
      "Training fraud cases: 61182.0 (8.74%)\n",
      "Test fraud cases: 26221.0 (8.74%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = data.drop('fraud', axis=1)\n",
    "y = data['fraud']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training fraud cases: {y_train.sum()} ({y_train.mean()*100:.2f}%)\")\n",
    "print(f\"Test fraud cases: {y_test.sum()} ({y_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pEszBciiBQX-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Grid Search Configuration:\n",
      "  cv: 3\n",
      "  scoring: f1\n",
      "  n_jobs: -1\n",
      "  verbose: 1\n",
      "  random_state: 42\n",
      "  n_iter: 10\n",
      "\n",
      "Parameter grids defined for 3 algorithms\n",
      "  logistic_regression: 4 hyperparameters\n",
      "  random_forest: 4 hyperparameters\n",
      "  xgboost: 5 hyperparameters\n"
     ]
    }
   ],
   "source": [
    "## 3. Standardized Grid Search Configuration\n",
    "\n",
    "# Define consistent grid search parameters for all models\n",
    "GRID_SEARCH_CONFIG = {\n",
    "    'cv': 3,                    # 3-fold cross-validation\n",
    "    'scoring': 'f1',            # F1-score as optimization metric\n",
    "    'n_jobs': -1,               # Use all available CPU cores\n",
    "    'verbose': 1,               # Show progress\n",
    "    'random_state': 42,         # Reproducible results\n",
    "    'n_iter': 10               # Number of parameter combinations to try\n",
    "}\n",
    "\n",
    "print(\"Standardized Grid Search Configuration:\")\n",
    "for key, value in GRID_SEARCH_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Standardized parameter grids for each algorithm\n",
    "PARAM_GRIDS = {\n",
    "    'logistic_regression': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs'],\n",
    "        'classifier__max_iter': [1000]\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'classifier__n_estimators': [50, 100],\n",
    "        'classifier__max_depth': [5],\n",
    "        'classifier__min_samples_split': [10],\n",
    "        'classifier__min_samples_leaf': [4]\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'classifier__n_estimators': [50, 100],\n",
    "        'classifier__max_depth': [3, 5],\n",
    "        'classifier__learning_rate': [0.1],\n",
    "        'classifier__subsample': [0.8],\n",
    "        'classifier__colsample_bytree': [0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nParameter grids defined for {len(PARAM_GRIDS)} algorithms\")\n",
    "for algo, params in PARAM_GRIDS.items():\n",
    "    print(f\"  {algo}: {len(params)} hyperparameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gCwMAEvgBQX_"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Print classification report for more details\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return {'Model': model_name, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}\n",
    "\n",
    "def run_standardized_experiment(pipeline, param_grid, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Run standardized grid search experiment\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Use standardized grid search configuration\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        pipeline, \n",
    "        param_grid,\n",
    "        **GRID_SEARCH_CONFIG\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best parameters and CV score\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV F1-score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    results = evaluate_model(grid_search.best_estimator_, X_test, y_test, model_name)\n",
    "    \n",
    "    return grid_search, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5nVIdg9BQX_"
   },
   "source": [
    "## 4. Model Training and Evaluation - Standardized Experiments\n",
    "\n",
    "### 4.1 Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWBG-6KeBQX_",
    "outputId": "cb5fcddb-c8c1-487a-b0e7-d516416eb7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Logistic Regression (SMOTE)...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best parameters: {'classifier__solver': 'lbfgs', 'classifier__penalty': 'l2', 'classifier__max_iter': 1000, 'classifier__C': 10}\n",
      "Best CV F1-score: 0.7148\n",
      "\n",
      "Logistic Regression (SMOTE) Results:\n",
      "Precision: 0.5760\n",
      "Recall: 0.9485\n",
      "F1-Score: 0.7167\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    273779\n",
      "         1.0       0.58      0.95      0.72     26221\n",
      "\n",
      "    accuracy                           0.93    300000\n",
      "   macro avg       0.79      0.94      0.84    300000\n",
      "weighted avg       0.96      0.93      0.94    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with SMOTE and Logistic Regression\n",
    "lr_smote_pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Run standardized experiment\n",
    "lr_smote_grid, lr_smote_results = run_standardized_experiment(\n",
    "    lr_smote_pipeline, \n",
    "    PARAM_GRIDS['logistic_regression'],\n",
    "    \"Logistic Regression (SMOTE)\",\n",
    "    X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzEjU8GSBQYA"
   },
   "source": [
    "### 4.2 Logistic Regression with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bi2_xnmsBQYA",
    "outputId": "5dd7ea3e-2390-4c3e-f108-3d66850ced16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Logistic Regression (Undersampling)...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best parameters: {'classifier__solver': 'lbfgs', 'classifier__penalty': 'l2', 'classifier__max_iter': 1000, 'classifier__C': 10}\n",
      "Best CV F1-score: 0.7148\n",
      "\n",
      "Logistic Regression (Undersampling) Results:\n",
      "Precision: 0.5771\n",
      "Recall: 0.9494\n",
      "F1-Score: 0.7179\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    273779\n",
      "         1.0       0.58      0.95      0.72     26221\n",
      "\n",
      "    accuracy                           0.93    300000\n",
      "   macro avg       0.79      0.94      0.84    300000\n",
      "weighted avg       0.96      0.93      0.94    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with undersampling and Logistic Regression\n",
    "lr_under_pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('undersampler', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Run standardized experiment\n",
    "lr_under_grid, lr_under_results = run_standardized_experiment(\n",
    "    lr_under_pipeline,\n",
    "    PARAM_GRIDS['logistic_regression'],\n",
    "    \"Logistic Regression (Undersampling)\",\n",
    "    X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugKc5dBJBQYA"
   },
   "source": [
    "### 4.3 Random Forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bc3O8acTBQYA",
    "outputId": "aaf999b4-6e82-4163-9399-0651ba7e8d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Random Forest (SMOTE)...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best parameters: {'classifier__n_estimators': 100, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_depth': 5}\n",
      "Best CV F1-score: 0.9967\n",
      "\n",
      "Random Forest (SMOTE) Results:\n",
      "Precision: 1.0000\n",
      "Recall: 0.9937\n",
      "F1-Score: 0.9969\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    273779\n",
      "         1.0       1.00      0.99      1.00     26221\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       1.00      1.00      1.00    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with SMOTE and Random Forest\n",
    "rf_smote_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Run standardized experiment\n",
    "rf_smote_grid, rf_smote_results = run_standardized_experiment(\n",
    "    rf_smote_pipeline,\n",
    "    PARAM_GRIDS['random_forest'],\n",
    "    \"Random Forest (SMOTE)\",\n",
    "    X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoR5UMoeBQYB"
   },
   "source": [
    "### 4.4 Random Forest with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p82grLdzBQYB",
    "outputId": "444888de-c36d-4bb7-a53c-9d7c3aa5a4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Random Forest (Undersampling)...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best parameters: {'classifier__n_estimators': 50, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_depth': 5}\n",
      "Best CV F1-score: 0.9971\n",
      "\n",
      "Random Forest (Undersampling) Results:\n",
      "Precision: 0.9727\n",
      "Recall: 0.9999\n",
      "F1-Score: 0.9861\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    273779\n",
      "         1.0       0.97      1.00      0.99     26221\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       0.99      1.00      0.99    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with undersampling and Random Forest\n",
    "rf_under_pipeline = ImbPipeline([\n",
    "    ('undersampler', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Run standardized experiment\n",
    "rf_under_grid, rf_under_results = run_standardized_experiment(\n",
    "    rf_under_pipeline,\n",
    "    PARAM_GRIDS['random_forest'],\n",
    "    \"Random Forest (Undersampling)\",\n",
    "    X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfTslJM9BQYB"
   },
   "source": [
    "### 4.5 XGBoost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ktu49e6BQYB",
    "outputId": "a0a7cf42-334a-4c32-edc8-0dedcf7bb35a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training XGBoost (SMOTE)...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best parameters: {'classifier__subsample': 0.8, 'classifier__n_estimators': 100, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.9}\n",
      "Best CV F1-score: 0.9887\n",
      "\n",
      "XGBoost (SMOTE) Results:\n",
      "Precision: 0.9722\n",
      "Recall: 0.9988\n",
      "F1-Score: 0.9853\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    273779\n",
      "         1.0       0.97      1.00      0.99     26221\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       0.99      1.00      0.99    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with SMOTE and XGBoost\n",
    "xgb_smote_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', xgb.XGBClassifier(random_state=42, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Run standardized experiment\n",
    "xgb_smote_grid, xgb_smote_results = run_standardized_experiment(\n",
    "    xgb_smote_pipeline,\n",
    "    PARAM_GRIDS['xgboost'],\n",
    "    \"XGBoost (SMOTE)\",\n",
    "    X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGlLHOjmBQYC"
   },
   "source": [
    "### 4.6 XGBoost with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvO7Qa6oBQYC",
    "outputId": "0bfd6d6d-edc3-4118-d844-62f9339406e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training XGBoost (Undersampling)...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best parameters: {'classifier__subsample': 0.8, 'classifier__n_estimators': 50, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.9}\n",
      "Best CV F1-score: 0.9872\n",
      "\n",
      "XGBoost (Undersampling) Results:\n",
      "Precision: 0.9784\n",
      "Recall: 0.9983\n",
      "F1-Score: 0.9883\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    273779\n",
      "         1.0       0.98      1.00      0.99     26221\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       0.99      1.00      0.99    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with undersampling and XGBoost\n",
    "xgb_under_pipeline = ImbPipeline([\n",
    "    ('undersampler', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', xgb.XGBClassifier(random_state=42, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Run standardized experiment\n",
    "xgb_under_grid, xgb_under_results = run_standardized_experiment(\n",
    "    xgb_under_pipeline,\n",
    "    PARAM_GRIDS['xgboost'],\n",
    "    \"XGBoost (Undersampling)\",\n",
    "    X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msOLB0IMBQYC"
   },
   "source": [
    "## 5. Results Summary and Comparison - Standardized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBIfpL9tBQYC",
    "outputId": "3d87b3d7-423c-43ff-d608-3f425bf9e6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STANDARDIZED GRID SEARCH RESULTS COMPARISON\n",
      "================================================================================\n",
      "Grid Search Configuration Used:\n",
      "  cv: 3\n",
      "  scoring: f1\n",
      "  n_jobs: -1\n",
      "  verbose: 1\n",
      "  random_state: 42\n",
      "  n_iter: 10\n",
      "\n",
      "Results Table:\n",
      "                              Model  Precision  Recall  F1-Score\n",
      "        Logistic Regression (SMOTE)     0.5760  0.9485    0.7167\n",
      "Logistic Regression (Undersampling)     0.5771  0.9494    0.7179\n",
      "              Random Forest (SMOTE)     1.0000  0.9937    0.9969\n",
      "      Random Forest (Undersampling)     0.9727  0.9999    0.9861\n",
      "                    XGBoost (SMOTE)     0.9722  0.9988    0.9853\n",
      "            XGBoost (Undersampling)     0.9784  0.9983    0.9883\n",
      "\n",
      "================================================================================\n",
      "RESULTS RANKED BY F1-SCORE (STANDARDIZED)\n",
      "================================================================================\n",
      "                              Model  Precision  Recall  F1-Score\n",
      "              Random Forest (SMOTE)     1.0000  0.9937    0.9969\n",
      "            XGBoost (Undersampling)     0.9784  0.9983    0.9883\n",
      "      Random Forest (Undersampling)     0.9727  0.9999    0.9861\n",
      "                    XGBoost (SMOTE)     0.9722  0.9988    0.9853\n",
      "Logistic Regression (Undersampling)     0.5771  0.9494    0.7179\n",
      "        Logistic Regression (SMOTE)     0.5760  0.9485    0.7167\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE STATISTICS\n",
      "================================================================================\n",
      "Best F1-Score: 0.9969\n",
      "Worst F1-Score: 0.7167\n",
      "Average F1-Score: 0.8985\n",
      "F1-Score Standard Deviation: 0.1404\n",
      "\n",
      "Best Precision: 1.0000\n",
      "Best Recall: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Combine all results from standardized experiments\n",
    "all_results = [\n",
    "    lr_smote_results,\n",
    "    lr_under_results,\n",
    "    rf_smote_results,\n",
    "    rf_under_results,\n",
    "    xgb_smote_results,\n",
    "    xgb_under_results\n",
    "]\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STANDARDIZED GRID SEARCH RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Grid Search Configuration Used:\")\n",
    "for key, value in GRID_SEARCH_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nResults Table:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Sort by F1-Score for better comparison\n",
    "results_sorted = results_df.sort_values('F1-Score', ascending=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS RANKED BY F1-SCORE (STANDARDIZED)\")\n",
    "print(\"=\"*80)\n",
    "print(results_sorted.to_string(index=False))\n",
    "\n",
    "# Calculate performance statistics\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best F1-Score: {results_df['F1-Score'].max():.4f}\")\n",
    "print(f\"Worst F1-Score: {results_df['F1-Score'].min():.4f}\")\n",
    "print(f\"Average F1-Score: {results_df['F1-Score'].mean():.4f}\")\n",
    "print(f\"F1-Score Standard Deviation: {results_df['F1-Score'].std():.4f}\")\n",
    "\n",
    "print(f\"\\nBest Precision: {results_df['Precision'].max():.4f}\")\n",
    "print(f\"Best Recall: {results_df['Recall'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2g58kQLBQYD",
    "outputId": "c4e470de-babe-4133-ee7a-8ea4ec0f7356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED ANALYSIS - STANDARDIZED EXPERIMENTS\n",
      "================================================================================\n",
      "Best Precision: Random Forest (SMOTE) (1.0000)\n",
      "Best Recall: Random Forest (Undersampling) (0.9999)\n",
      "Best F1-Score: Random Forest (SMOTE) (0.9969)\n",
      "\n",
      "================================================================================\n",
      "ALGORITHM VS SAMPLING TECHNIQUE ANALYSIS\n",
      "================================================================================\n",
      "Logistic Regression : Undersampling wins (F1 diff: 0.0012)\n",
      "                      SMOTE: 0.7167, Undersampling: 0.7179\n",
      "Random Forest       : SMOTE         wins (F1 diff: 0.0108)\n",
      "                      SMOTE: 0.9969, Undersampling: 0.9861\n",
      "XGBoost             : Undersampling wins (F1 diff: 0.0030)\n",
      "                      SMOTE: 0.9853, Undersampling: 0.9883\n",
      "\n",
      "Overall Average Performance:\n",
      "  SMOTE Average F1-Score: 0.8996\n",
      "  Undersampling Average F1-Score: 0.8974\n",
      "  Better Overall: SMOTE\n",
      "\n",
      "================================================================================\n",
      "BEST HYPERPARAMETERS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Logistic Regression (SMOTE):\n",
      "  classifier__solver: lbfgs\n",
      "  classifier__penalty: l2\n",
      "  classifier__max_iter: 1000\n",
      "  classifier__C: 10\n",
      "\n",
      "Logistic Regression (Undersampling):\n",
      "  classifier__solver: lbfgs\n",
      "  classifier__penalty: l2\n",
      "  classifier__max_iter: 1000\n",
      "  classifier__C: 10\n",
      "\n",
      "Random Forest (SMOTE):\n",
      "  classifier__n_estimators: 100\n",
      "  classifier__min_samples_split: 10\n",
      "  classifier__min_samples_leaf: 4\n",
      "  classifier__max_depth: 5\n",
      "\n",
      "Random Forest (Undersampling):\n",
      "  classifier__n_estimators: 50\n",
      "  classifier__min_samples_split: 10\n",
      "  classifier__min_samples_leaf: 4\n",
      "  classifier__max_depth: 5\n",
      "\n",
      "XGBoost (SMOTE):\n",
      "  classifier__subsample: 0.8\n",
      "  classifier__n_estimators: 100\n",
      "  classifier__max_depth: 5\n",
      "  classifier__learning_rate: 0.1\n",
      "  classifier__colsample_bytree: 0.9\n",
      "\n",
      "XGBoost (Undersampling):\n",
      "  classifier__subsample: 0.8\n",
      "  classifier__n_estimators: 50\n",
      "  classifier__max_depth: 5\n",
      "  classifier__learning_rate: 0.1\n",
      "  classifier__colsample_bytree: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Advanced analysis with standardized results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED ANALYSIS - STANDARDIZED EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best model for each metric\n",
    "best_precision = results_df.loc[results_df['Precision'].idxmax()]\n",
    "best_recall = results_df.loc[results_df['Recall'].idxmax()]\n",
    "best_f1 = results_df.loc[results_df['F1-Score'].idxmax()]\n",
    "\n",
    "print(f\"Best Precision: {best_precision['Model']} ({best_precision['Precision']:.4f})\")\n",
    "print(f\"Best Recall: {best_recall['Model']} ({best_recall['Recall']:.4f})\")\n",
    "print(f\"Best F1-Score: {best_f1['Model']} ({best_f1['F1-Score']:.4f})\")\n",
    "\n",
    "# Algorithm vs Sampling Technique Analysis\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"ALGORITHM VS SAMPLING TECHNIQUE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "algorithms = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
    "sampling_techniques = ['SMOTE', 'Undersampling']\n",
    "\n",
    "comparison_data = []\n",
    "for algo in algorithms:\n",
    "    smote_row = results_df[results_df['Model'].str.contains(algo) & results_df['Model'].str.contains('SMOTE')]\n",
    "    under_row = results_df[results_df['Model'].str.contains(algo) & results_df['Model'].str.contains('Undersampling')]\n",
    "\n",
    "    if not smote_row.empty and not under_row.empty:\n",
    "        smote_f1 = smote_row['F1-Score'].iloc[0]\n",
    "        under_f1 = under_row['F1-Score'].iloc[0]\n",
    "        better = \"SMOTE\" if smote_f1 > under_f1 else \"Undersampling\"\n",
    "        diff = abs(smote_f1 - under_f1)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Algorithm': algo,\n",
    "            'SMOTE_F1': smote_f1,\n",
    "            'Undersampling_F1': under_f1,\n",
    "            'Better_Technique': better,\n",
    "            'F1_Difference': diff\n",
    "        })\n",
    "        \n",
    "        print(f\"{algo:20}: {better:13} wins (F1 diff: {diff:.4f})\")\n",
    "        print(f\"{'':20}  SMOTE: {smote_f1:.4f}, Undersampling: {under_f1:.4f}\")\n",
    "\n",
    "# Overall sampling technique performance\n",
    "smote_avg = results_df[results_df['Model'].str.contains('SMOTE')]['F1-Score'].mean()\n",
    "under_avg = results_df[results_df['Model'].str.contains('Undersampling')]['F1-Score'].mean()\n",
    "print(f\"\\nOverall Average Performance:\")\n",
    "print(f\"  SMOTE Average F1-Score: {smote_avg:.4f}\")\n",
    "print(f\"  Undersampling Average F1-Score: {under_avg:.4f}\")\n",
    "print(f\"  Better Overall: {'SMOTE' if smote_avg > under_avg else 'Undersampling'}\")\n",
    "\n",
    "# Best parameter analysis\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"BEST HYPERPARAMETERS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models_and_grids = [\n",
    "    (\"Logistic Regression (SMOTE)\", lr_smote_grid),\n",
    "    (\"Logistic Regression (Undersampling)\", lr_under_grid),\n",
    "    (\"Random Forest (SMOTE)\", rf_smote_grid),\n",
    "    (\"Random Forest (Undersampling)\", rf_under_grid),\n",
    "    (\"XGBoost (SMOTE)\", xgb_smote_grid),\n",
    "    (\"XGBoost (Undersampling)\", xgb_under_grid)\n",
    "]\n",
    "\n",
    "for model_name, grid in models_and_grids:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for param, value in grid.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rROmm1JBQYD"
   },
   "source": [
    "## 6. Feature Importance Analysis - Standardized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5t8ee6BNBQYD",
    "outputId": "a4a83add-2a76-4421-aa7f-581bb0efcaf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Analysis from Standardized Grid Search\n",
      "============================================================\n",
      "Analyzing feature importance for: Random Forest (SMOTE)\n",
      "Best F1-Score: 0.9969\n",
      "\n",
      "Top Features by Importance:\n",
      "                       Feature  Importance\n",
      "ratio_to_median_purchase_price    0.542648\n",
      "                  online_order    0.165713\n",
      "            distance_from_home    0.152853\n",
      "distance_from_last_transaction    0.055761\n",
      "               used_pin_number    0.040170\n",
      "                     used_chip    0.034343\n",
      "               repeat_retailer    0.008512\n",
      "\n",
      "Feature Importance Insights:\n",
      "  Most Important Feature: ratio_to_median_purchase_price (0.5426)\n",
      "  Least Important Feature: repeat_retailer (0.0085)\n",
      "  Top 3 features account for 86.12% of total importance\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE COMPARISON ACROSS TREE-BASED MODELS\n",
      "================================================================================\n",
      "Feature Importance Comparison:\n",
      "                       Feature  Random Forest (SMOTE)  Random Forest (Undersampling)  XGBoost (SMOTE)  XGBoost (Undersampling)  Average_Importance\n",
      "ratio_to_median_purchase_price                 0.5426                         0.5241           0.5513                   0.5648              0.5457\n",
      "            distance_from_home                 0.1529                         0.1716           0.1618                   0.1797              0.1665\n",
      "                  online_order                 0.1657                         0.1764           0.1008                   0.0812              0.1310\n",
      "distance_from_last_transaction                 0.0558                         0.0472           0.0758                   0.0708              0.0624\n",
      "               used_pin_number                 0.0402                         0.0465           0.0312                   0.0273              0.0363\n",
      "                     used_chip                 0.0343                         0.0237           0.0303                   0.0338              0.0305\n",
      "               repeat_retailer                 0.0085                         0.0105           0.0489                   0.0425              0.0276\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis from standardized experiments\n",
    "print(f\"Feature Importance Analysis from Standardized Grid Search\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model_name = best_f1['Model']\n",
    "print(f\"Analyzing feature importance for: {best_model_name}\")\n",
    "print(f\"Best F1-Score: {best_f1['F1-Score']:.4f}\")\n",
    "\n",
    "# Get the corresponding best model\n",
    "best_model = None\n",
    "if 'XGBoost' in best_model_name:\n",
    "    if 'SMOTE' in best_model_name:\n",
    "        best_model = xgb_smote_grid.best_estimator_\n",
    "    else:\n",
    "        best_model = xgb_under_grid.best_estimator_\n",
    "elif 'Random Forest' in best_model_name:\n",
    "    if 'SMOTE' in best_model_name:\n",
    "        best_model = rf_smote_grid.best_estimator_\n",
    "    else:\n",
    "        best_model = rf_under_grid.best_estimator_\n",
    "else:  # Logistic Regression\n",
    "    if 'SMOTE' in best_model_name:\n",
    "        best_model = lr_smote_grid.best_estimator_\n",
    "    else:\n",
    "        best_model = lr_under_grid.best_estimator_\n",
    "\n",
    "# Extract feature importance\n",
    "try:\n",
    "    if hasattr(best_model.named_steps['classifier'], 'feature_importances_'):\n",
    "        importance = best_model.named_steps['classifier'].feature_importances_\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': importance\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "\n",
    "        print(f\"\\nTop Features by Importance:\")\n",
    "        print(feature_importance.to_string(index=False))\n",
    "        \n",
    "        # Additional analysis\n",
    "        print(f\"\\nFeature Importance Insights:\")\n",
    "        print(f\"  Most Important Feature: {feature_importance.iloc[0]['Feature']} ({feature_importance.iloc[0]['Importance']:.4f})\")\n",
    "        print(f\"  Least Important Feature: {feature_importance.iloc[-1]['Feature']} ({feature_importance.iloc[-1]['Importance']:.4f})\")\n",
    "        print(f\"  Top 3 features account for {feature_importance.head(3)['Importance'].sum():.2%} of total importance\")\n",
    "        \n",
    "    elif hasattr(best_model.named_steps['classifier'], 'coef_'):\n",
    "        # For logistic regression, use coefficients\n",
    "        coef = best_model.named_steps['classifier'].coef_[0]\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Coefficient': coef,\n",
    "            'Abs_Coefficient': np.abs(coef)\n",
    "        }).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "        print(f\"\\nLogistic Regression Coefficients (by absolute value):\")\n",
    "        print(feature_importance[['Feature', 'Coefficient', 'Abs_Coefficient']].to_string(index=False))\n",
    "        \n",
    "        print(f\"\\nCoefficient Insights:\")\n",
    "        print(f\"  Strongest positive coefficient: {feature_importance[feature_importance['Coefficient'] > 0].iloc[0]['Feature']}\")\n",
    "        print(f\"  Strongest negative coefficient: {feature_importance[feature_importance['Coefficient'] < 0].iloc[0]['Feature']}\")\n",
    "    else:\n",
    "        print(\"Feature importance not available for this model type.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not extract feature importance: {e}\")\n",
    "\n",
    "# Compare feature importance across tree-based models\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE COMPARISON ACROSS TREE-BASED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tree_models = [\n",
    "    (\"Random Forest (SMOTE)\", rf_smote_grid.best_estimator_),\n",
    "    (\"Random Forest (Undersampling)\", rf_under_grid.best_estimator_),\n",
    "    (\"XGBoost (SMOTE)\", xgb_smote_grid.best_estimator_),\n",
    "    (\"XGBoost (Undersampling)\", xgb_under_grid.best_estimator_)\n",
    "]\n",
    "\n",
    "feature_importance_comparison = pd.DataFrame({'Feature': X.columns})\n",
    "\n",
    "for model_name, model in tree_models:\n",
    "    try:\n",
    "        if hasattr(model.named_steps['classifier'], 'feature_importances_'):\n",
    "            importance = model.named_steps['classifier'].feature_importances_\n",
    "            feature_importance_comparison[model_name] = importance\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract importance for {model_name}: {e}\")\n",
    "\n",
    "if len(feature_importance_comparison.columns) > 1:\n",
    "    # Calculate average importance across models\n",
    "    importance_cols = [col for col in feature_importance_comparison.columns if col != 'Feature']\n",
    "    feature_importance_comparison['Average_Importance'] = feature_importance_comparison[importance_cols].mean(axis=1)\n",
    "    feature_importance_comparison = feature_importance_comparison.sort_values('Average_Importance', ascending=False)\n",
    "    \n",
    "    print(\"Feature Importance Comparison:\")\n",
    "    print(feature_importance_comparison.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-cHtnXXBQYE"
   },
   "source": [
    "## 7. Key Insights and Recommendations - Standardized Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNx9b-RQBQYE",
    "outputId": "33db8e9e-abdf-4735-eee3-f326a08b3867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS AND RECOMMENDATIONS - STANDARDIZED GRID SEARCH\n",
      "================================================================================\n",
      "\n",
      "1. STANDARDIZED EXPERIMENTAL SETUP:\n",
      "   â€¢ Used consistent grid search parameters across all experiments\n",
      "   â€¢ 10 parameter combinations tested per model\n",
      "   â€¢ 3-fold cross-validation for robust evaluation\n",
      "   â€¢ F1-score as primary optimization metric\n",
      "\n",
      "2. BEST OVERALL MODEL:\n",
      "   â€¢ Random Forest (SMOTE) achieved the highest F1-Score of 0.9969\n",
      "   â€¢ Precision: 1.0000, Recall: 0.9937\n",
      "   â€¢ This model provides the best balance between Precision and Recall\n",
      "\n",
      "3. SAMPLING TECHNIQUE ANALYSIS:\n",
      "   â€¢ SMOTE performs better on average\n",
      "   â€¢ Average F1-Score: SMOTE (0.8996) vs Undersampling (0.8974)\n",
      "   â€¢ Difference: 0.0022\n",
      "\n",
      "4. ALGORITHM RANKING BY BEST PERFORMANCE:\n",
      "   1. Random Forest: 0.9969 (best F1-score)\n",
      "   2. XGBoost: 0.9883 (best F1-score)\n",
      "   3. Logistic Regression: 0.7179 (best F1-score)\n",
      "\n",
      "5. PERFORMANCE CONSISTENCY:\n",
      "   â€¢ F1-Score standard deviation: 0.1404\n",
      "   â€¢ F1-Score range: 0.2802\n",
      "   â€¢ Significant performance variation between models\n",
      "\n",
      "6. HYPERPARAMETER INSIGHTS:\n",
      "   â€¢ Best performing configurations identified through systematic search\n",
      "   â€¢ Parameter optimization significantly impacts model performance\n",
      "   â€¢ Standardized approach ensures fair comparison between models\n",
      "\n",
      "7. EXPERIMENT REPRODUCIBILITY:\n",
      "   â€¢ All experiments use random_state=42\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS AND RECOMMENDATIONS - STANDARDIZED GRID SEARCH\")\n",
    "print(\"=\"*80), 1.0\n",
    "\n",
    "print(f\"\\n1. STANDARDIZED EXPERIMENTAL SETUP:\")\n",
    "print(f\"   â€¢ Used consistent grid search parameters across all experiments\")\n",
    "print(f\"   â€¢ {GRID_SEARCH_CONFIG['n_iter']} parameter combinations tested per model\")\n",
    "print(f\"   â€¢ {GRID_SEARCH_CONFIG['cv']}-fold cross-validation for robust evaluation\")\n",
    "print(f\"   â€¢ F1-score as primary optimization metric\")\n",
    "\n",
    "print(f\"\\n2. BEST OVERALL MODEL:\")\n",
    "print(f\"   â€¢ {best_f1['Model']} achieved the highest F1-Score of {best_f1['F1-Score']:.4f}\")\n",
    "print(f\"   â€¢ Precision: {best_f1['Precision']:.4f}, Recall: {best_f1['Recall']:.4f}\")\n",
    "print(f\"   â€¢ This model provides the best balance between Precision and Recall\")\n",
    "\n",
    "print(f\"\\n3. SAMPLING TECHNIQUE ANALYSIS:\")\n",
    "smote_avg = results_df[results_df['Model'].str.contains('SMOTE')]['F1-Score'].mean()\n",
    "under_avg = results_df[results_df['Model'].str.contains('Undersampling')]['F1-Score'].mean()\n",
    "better_sampling = \"SMOTE\" if smote_avg > under_avg else \"Undersampling\"\n",
    "diff = abs(smote_avg - under_avg)\n",
    "print(f\"   â€¢ {better_sampling} performs better on average\")\n",
    "print(f\"   â€¢ Average F1-Score: SMOTE ({smote_avg:.4f}) vs Undersampling ({under_avg:.4f})\")\n",
    "print(f\"   â€¢ Difference: {diff:.4f}\")\n",
    "\n",
    "print(f\"\\n4. ALGORITHM RANKING BY BEST PERFORMANCE:\")\n",
    "algo_performance = {}\n",
    "algorithms = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
    "for algo in algorithms:\n",
    "    algo_scores = results_df[results_df['Model'].str.contains(algo)]['F1-Score']\n",
    "    algo_performance[algo] = algo_scores.max()\n",
    "\n",
    "sorted_algos = sorted(algo_performance.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (algo, score) in enumerate(sorted_algos, 1):\n",
    "    print(f\"   {i}. {algo}: {score:.4f} (best F1-score)\")\n",
    "\n",
    "print(f\"\\n5. PERFORMANCE CONSISTENCY:\")\n",
    "f1_std = results_df['F1-Score'].std()\n",
    "f1_range = results_df['F1-Score'].max() - results_df['F1-Score'].min()\n",
    "print(f\"   â€¢ F1-Score standard deviation: {f1_std:.4f}\")\n",
    "print(f\"   â€¢ F1-Score range: {f1_range:.4f}\")\n",
    "if f1_std < 0.1:\n",
    "    print(f\"   â€¢ Models show consistent performance across algorithms\")\n",
    "else:\n",
    "    print(f\"   â€¢ Significant performance variation between models\")\n",
    "\n",
    "print(f\"\\n6. HYPERPARAMETER INSIGHTS:\")\n",
    "print(f\"   â€¢ Best performing configurations identified through systematic search\")\n",
    "print(f\"   â€¢ Parameter optimization significantly impacts model performance\")\n",
    "print(f\"   â€¢ Standardized approach ensures fair comparison between models\")\n",
    "\n",
    "# print(f\"\\n7. RECOMMENDATIONS:\")\n",
    "# print(f\"   â€¢ Deploy {best_f1['Model']} for production fraud detection\")\n",
    "# print(f\"   â€¢ Monitor model performance and retrain periodically\")\n",
    "# print(f\"   â€¢ Consider ensemble methods combining top-performing models\")\n",
    "# print(f\"   â€¢ Implement proper validation pipeline for new data\")\n",
    "\n",
    "# if results_df['Precision'].min() < 0.8:\n",
    "#     print(f\"   â€¢ WARNING: Some models have precision < 0.8, consider cost of false positives\")\n",
    "    \n",
    "# if results_df['Recall'].min() < 0.8:\n",
    "#     print(f\"   â€¢ WARNING: Some models have recall < 0.8, consider cost of missed fraud\")\n",
    "print(f\"\\n7. EXPERIMENT REPRODUCIBILITY:\")\n",
    "print(f\"   â€¢ All experiments use random_state=42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
